<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[驾驶行为分析]]></title>
    <url>%2F2019%2F01%2F28%2Fdriver-behavior-analysis%2F</url>
    <content type="text"><![CDATA[概述 通过车载设备、用户手机和穿戴设备的传感器，获取车辆和驾驶员相关数据，通过数据分析模型和大数据实时计算等手段，对驾驶行为和驾驶技术进行实时监测和智能评估，对于交通事故减少、驾驶技术提升，以及UBI定价等方面，都有重要的参考价值。从社会环境和经济价值上看，降低行车事故发生率，降低车辆保费和燃油成本，这些方面都是积极正面的。 相关方分析 车厂 通过IVI、TBOX、C-Link、OBD、ADAS等终端数据采集并上传云端分析，使汽车具备实时驾驶行为分析与安全行车提示、精确燃油经济性分析、节能驾驶指导等功能。为车厂提供车联网大数据服务，提升用户对产品更省油、更安全的品牌认知。 保险 通过精准的驾驶行为分析，将车主数据从原始的理赔数据向驾驶数据迁移拓展，为保险公司提供新的保费计算参数，助力保险公司重构精算模型，降低理赔风险，提高车险盈利，增强用户粘性。 车队 驾驶行为分析为车队员工的绩效及工作质量管理提供新的方式，促进车队盈利能力提升，员工驾驶技术提升，降低车队的保费支出。 个人 通过手机和穿戴设备传感器的数据采集，获取车辆行驶状态和驾驶员状态，包括车辆速度、加速度、驾驶员心率和心律状态、语言情感状态等信息，通过多种手段，包括分析车辆状态、驾驶员情绪（愤怒和极度悲伤时心率快且心律不稳）、NLP情感分析（sentiment analysis）等对个人驾驶行为进行多维度个性化分析，引导驾驶人改善驾驶行为，降低行车风险。 危险驾驶行为 行为 说明 标准 急加速（Harsh acceleration） 一级加速：每秒时速差&gt;10KM/h；二级加速：&gt;8KM/h; 三级加速：&gt;6KM/h，持续2秒以上 急减速（Harsh braking） 一级减速：每秒时速差&gt;10KM/h；二级减速：&gt;8KM/h; 三级减速：&gt;6KM/h，持续2秒以上 频繁刹车（Frequent braking） 超速行驶（Speeding） 一级超速：超过道路限速50%以上；二级超速：超过20%以上；三级超速：超过10%以上 高速转弯（Harsh high speed turning） 车辆重心高低影响不同转弯角度下最大转弯车速 慢速行驶（Slow driving） 行驶速度低于道路最低限速，常见于高速道路 频繁停车（Frequent stopping） 疲劳驾驶（Fatigued driving） 通过穿戴设备CPC（ CardioPulmonary Coupling心肺耦合图谱）分析，达到类似EEG（ Electroencephalogram脑电波）分析的效果，判断驾驶员疲劳程度 车辆检测方法 急加减速、超速/慢速行驶 周期性采集车辆经纬度，从地图信息中获取车辆位置所在路段限速，在给定时间窗内判断急加减速和超速/慢速行驶行为次数。 疲劳驾驶检测 传统的基于车辆行为的疲劳驾驶检测较为简单，主要通过驾驶时间、方向盘转动频率、踩刹车和油门的频率等方式，另外，可借助前置摄像头，检测前方道路状况的单调性，间接估计驾驶员疲劳程度。此类方法通常精度不高，且欠缺灵敏度。 驾驶员检测方法 生理状态检测 目前在穿戴设备可检测的生理状态包括心率、心律和心电信号。心率和心律会反应一个人的生理情况和情绪情况，例如驾驶员瞌睡时，心率下降心律稳定；当愤怒或者悲伤时，心率提高心律不稳等等。甚至可以通过某些穿戴设备的CPC分析功能，提供更详细精确的生理状况分析。 面部图像识别 通过采集驾驶员面部特征变化来判断疲劳，主要包括瞳孔大小、眨眼频率、眼睛转动速度、眼睛闭合度、闭眼时间占比等等，通过简单的逻辑回归算法或者复杂的卷积神经网络（CNN），都可以做到判断驾驶员是否疲劳。缺点是需要较多的训练数据，而且摄像头对准驾驶员脸部会给驾驶员带来心理不适感。 语音识别(speech recognition)和情感分析(sentiment analysis) 具有危险驾驶行为的驾驶员通常伴随着严重的路怒症的，并且不吐不快，不骂不爽。通过对驾驶员的说话语音识别和情感分析，可以获知当前驾驶员的情绪状态。通过递归神经网络（RNN）和迁移学习（transfer learning）等手段，检测驾驶员情绪状态。 总结 驾驶行为分析包含多种行为内容和检测手段，根据使用场景的不同，以及硬件条件的不同，各种行为内容会有不同的权重，最终的驾驶行为打分可能根据不同的驾驶行为以线性函数(linear function)方式展示，也有可能以高阶多项式函数（high-degree polynomial function）方式展示，并无标准的公式可供套用。]]></content>
      <categories>
        <category>Vehicle</category>
      </categories>
      <tags>
        <tag>driver behavior</tag>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flink SQL 原理及使用入门]]></title>
    <url>%2F2018%2F10%2F31%2FFlink%20SQL%20%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[基于Apache Flink 1.6.x 1 Get Started Flink SQL是Flink高层API，语法遵循ANSI SQL标准。示例如下 1234SELECT car_id, MAX(speed), COUNT(speed)FROM drive_dataWHERE speed &gt; 90GROUP BY TUMBLE (proctime, INTERVAL '30' SECOND), car_id Flink SQL是在Flink Table API的基础上发展起来的，与上述示例对应的Table API示例如下 1234table.where('speed &gt; 90) .window(Tumble over 30.second on 'proctime as 'w) .groupBy('w, 'car_id) .select('car_id, 'speed.max, 'speed.count) 上述示例使用Scala代码，结合隐式转换和中缀表示等Scala语法，Table API代码看起来非常接近SQL表达。 2 架构原理 老版本的Table API通过类似链式调用的写法，构造一棵Table Operator树，并对各个树节点做代码生成，转化成Flink低层API调用代码，即DataStream/DataSet API。 从2016年开始，开源社区已经有大量SQL-on-Hadoop的成熟解决方案，包括Apache Hive、Apache Impala、Apache Drill等等，都依赖Apache Calcite提供的SQL解析优化能力，Apache Calcite当时已经是一个非常流行的业界标准SQL解析和优化框架。于此同时，随着在实时分析领域中Flink的应用场景增加，对SQL API的呼声渐高，于是社区开始在Apache Calcite的基础上构建新版本的Table API，并增加SQL API支持。 新版本的Table &amp; SQL API在原有的Table API基础上，由Calcite提供SQL解析和优化能力，将Table API调用和SQL查询统一转换成Calcite逻辑执行计划（Calcite RelNode树），并对此进行优化和代码生成，最终同样转化成Flink DataStream/DataSet API调用代码。 3 DDL &amp; DML 完整的SQL语法由DDL（data definition language）和DML（data manipulation language）两部分组成。Flink SQL目前只支持DML语法，而包含数据流定义的DDL语法仍需通过代码实现。 国内各大公有云厂商中，阿里云和华为云提供了基于Flink SQL的实时流计算服务，各自定义了一套DDL语法，语法大同小异。以华为云为例，数据流定义以CREATE STREAM为关键字，具体的DDL写法示例如下 123456789101112131415161718CREATE SOURCE STREAM driver_behavior (car_id STRING, speed INT, collect_time LONG)WITH ( type = "kafka", kafka_bootstrap_servers = "10.10.10.10:3456,10.10.10.20:3456", kafka_group_id = "group1", kafka_topic = "topic1", encode = "csv", field_delimiter = ",") TIMESTAMP BY collect_time.ROWTIME;CREATE SINK STREAM over_speed_warning (message STRING)WITH ( type = "smn", region = "cn-north-1", topic_urn = "urn:smn:cn-north-1:38834633fd6f4bae813031b5985dbdea:warning", message_subject = "title", message_column = "message"); DDL中包含输入数据流和输出数据流定义，描述实时流计算的数据上下游生态组件，在上述例子中，输入流（SOURCE STREAM）类型是Kafka，WITH子句描述了Kafka消费者相关配置。输出流（SINK STREAM）类型是SMN，是华为云消息通知服务的缩写，用于短信和邮件通知。 数据从Kafka流入，向SMN服务流出，而中间的数据处理逻辑由DML实现，具体的DML写法示例如下 123456789INSERT INTO over_speed_warningSELECT "your car speed (" || CAST(speed as CHAR(20)) || ") exceeds the maximum speed."FROM ( SELECT car_id, MAX(speed) AS speed, COUNT(speed) AS overspeed_count FROM driver_behavior WHERE speed &gt; 90 GROUP BY TUMBLE (collect_time, INTERVAL '30' SECOND), car_id)WHERE overspeed_count &gt;= 3; 以上DML语句，描述了在30秒内车辆累计超速三次时，向作为输出流的下游SMN组件输出告警消息。DML语句中INSERT INTO关键字后紧接着输出流名，而FROM关键字后紧接着输入流名，SELECT 子句表达输出的内容，WHERE子句表达输出需要满足的过滤条件。上述例子使用到了SQL子查询，外层FROM后跟着一整个SELECT子句，为了方便理解，我们也可以把子查询语法转化成等价的临时流定义表达，在华为云实时流计算服务的DDL语法中支持了这种特性，与上述DML写法等价的示例如下 123456789101112CREATE TEMP STREAM over_speed_info (car_id STRING, speed INT, overspeed_count INT);INSERT INTO over_speed_infoSELECT car_id, MAX(speed) AS speed, COUNT(speed) AS overspeed_countFROM driver_behaviorWHERE speed &gt; 90GROUP BY TUMBLE (collect_time, INTERVAL '30' SECOND), car_id;INSERT INTO over_speed_warningSELECT "your car speed (" || CAST(speed as CHAR(20)) || ") exceeds the maximum speed."FROM over_speed_infoWHERE overspeed_count &gt;= 3; 通过TEMP STREAM 语法定义临时流，可以将带有子查询的SQL语法平铺表达，串接数据流逻辑，更容易理解。 4 语法 Flink SQL的核心部分是DML语法，基础的DML语法包含笛卡尔积（单表情况下只有Scan操作）、选择（Filter）和投影（Projection）三个数据操作部分，三者分别对应FROM子句、WHERE 子句和SELECT子句，这三个部分的顺序代表了DML语句的逻辑执行顺序。较为进阶的语法包含聚合、窗口和连接（JOIN）等常用语法，以及排序、限制和集合等非常用语法。下表简单列举Flink SQL基础和常用的进阶DML语法句式并加以说明，其他语法元素和内建函数等详细内容，可参考Flink SQL文档 基础语法 操作 样例 Scan / Filter / Projection SELECT car_id, speed FROM drive_data WHERE speed &gt; 90 Scan / FIlter / Projection / Insert INSERT INTO overspeed SELECT id , speed FROM drive_data WHERE speed &gt; 90 聚合语法 操作 样例 备注 GroupBy Aggregation SELECT MAX(speed) FROM drive_data GROUP BY car_id GroupBy Window Aggregation SELECT car_id, MAX(speed) FROM drive_data GROUP BY TUMBLE(proctime, INTERVAL '1' MINUTE), car_id GroupBy窗口每个聚合周期输出一批聚合结果 Over Window Aggregation SELECT MAX(speed) OVER ( PARTITION BY car_id ORDER BY proctime RANGE BETWEEN INTERVAL '30' SECOND PRECEDING AND CURRENT ROW) FROM drive_data Over窗口每进入一条数据就输出一条聚合结果，且所有的投影属性的Over窗口必须一致 连接语法 操作 样例 备注 Inner Euiq-join SELECT * FROM drive_data INNER JOIN car_info ON drive_data.car_id = car_info.id 当前只支持等值连接 Time-windowed Join SELECT * FROM drive_data d, camera_data c WHERE d.car_id = c.car_id AND d.proctime BETWEEN c.proctime - INTERVAL '30' SECOND AND c.proctime Table Join SELECT * FROM drive_data INNER JOIN car_info ON drive_data.car_id = car_info.id 流表Join语法和流流Join语法类似，Flink SQL目前不支持流表Join，阿里云和华为云实时流计算服务的SQL语法是支持的 5 场景 目前Flink SQL的应用场景主要包括ETL实时入库、实时大屏、实时告警等等。 在IoT领域和车联网领域也大量存在潜在的使用场景，华为云实时流计算服务提供了针对这些场景的SQL扩展，包括地理函数，CEP SQL等支持，还支持Streaming ML语法用SQL表达多种实时机器学习算法，包括随机森林算法实现异常检测等场景。]]></content>
      <categories>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Flink</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Anti GFW guide]]></title>
    <url>%2F2018%2F07%2F17%2FAnti-GFW-guide%2F</url>
    <content type="text"><![CDATA[公司内网环境有美国代理，但Wi-Fi/4G环境是国内网络，使用Mac与手机时诸多不便，科学上网简要步骤记录如下 ss服务器 购买vps或者ecs，国内外提供商都有，网上随便搜搜，各大云厂商有折扣就买，一个月几十块。 之前用的是华为云香港区的ecs，选centos系统，KeyPair登陆，绑上弹性IP，安全组开放TCP入方向443端口。 1234easy_install pipyum install gitpip install git+https://github.com/shadowsocks/shadowsocks.git@masterssserver -p 443 -k yourpswd -m aes-256-cfb --user nobody -d start vultr经常有推广活动，目前注册送50刀，注册链接https://www.vultr.com/?ref=7898253-4F 123yum install net-toolswget -N --no-check certificate https://raw.githubusercontent.com/ToyoDAdoubi/doubi/master/ssr.sh &amp;&amp; chmod +x ssr.sh &amp;&amp; ./ssr.shwget --no-check-certificate https://github.com/teddysun/across/raw/master/bbr.sh &amp;&amp; chmod +x bbr.sh &amp;&amp; ./bbr.sh ss客户端 iPhone 手机没越狱，在闲鱼买了个香港或者美国appleid，下载shadowrocket、kite、openwingy等软件，配置服务器ip密码加密方式即可 MacBook 网页 shadowsocks官网下载客户端（需先用vpn软件翻墙）shadowsocksX/shadowsocksX-NG，安装后配置与iPhone类似 MacBook 终端 终端默认无法使用http代理，使用brew、sbt、git等命令时特别慢，需要安装privoxy（shadowsocksX-NG自带），在shell的rc脚本中配置（~/.zshrc) 123alias proxy='export all_proxy=socks5://127.0.0.1:1080'alias unproxy='unset all_proxy'export JAVA_OPTS="$JAVA_OPTS -Dhttp.proxyHost=127.0.0.1 -Dhttp.proxyPort=8118"]]></content>
      <categories>
        <category>科学上网</category>
      </categories>
      <tags>
        <tag>GFW</tag>
        <tag>shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mesos net_cls test]]></title>
    <url>%2F2017%2F05%2F27%2Fmesos-net-cls-test%2F</url>
    <content type="text"><![CDATA[1.mesos启动参数配置 slave启动参数配置，增加net_cls 1echo cgroups/cpu,cgroups/mem,cgroups/net_cls &gt; /etc/mesos-slave/isolation 增加mesos-slave启动参数--cgroups_net_cls_primary_handle=0x0001，可以通过修改/usr/bin/mesos-init-wrapper脚本实现，最终mesos-slave启动参数如下： 1/usr/sbin/mesos-slave --master=zk://10.120.177.85:2181,10.120.181.94:2181,10.120.180.209:2181/mesos --log_dir=/var/log/mesos --cgroups_net_cls_primary_handle=0x0001 --containerizers=mesos --isolation=cgroups/cpu,cgroups/mem,cgroups/net_cls --work_dir=/var/lib/meso 此时mesos会为每个容器分配一个16位的cgroups_net_cls_secondary_handle，和cgroups_net_cls_primary_handle(0x0001)一起组成一个classid。 2. 启动应用 使用marathon提交nc命令行应用，向对端发数据： 12345678&#123; "id": "/basic-023", "cmd": "yes ssssssssssssssssssssss|nc 10.162.174.188 5567", "cpus": 1, "mem": 10, "disk": 0, "instances": 1&#125; 使用nethogs工具查看进程流量： 3. 启用流控规则 查看容器进程的classid： 65538 = 0x00010002 使用tc工具配置规则： 12345tc qdisc del dev eth0 roottc qdisc add dev eth0 root handle 1: htbtc class add dev eth0 parent 1: classid 1: htb rate 1000mbit ceil 1000mbittc class add dev eth0 parent 1: classid 1:2 htb rate 1mbittc filter add dev eth0 protocol ip parent 1:0 prio 1 handle 1:2 cgroup 查看进行流控后的容器进程流量：]]></content>
      <categories>
        <category>Mesos</category>
      </categories>
      <tags>
        <tag>Mesos</tag>
        <tag>net_cls</tag>
        <tag>流控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Get Started with Flink on top of Mesos Marathon]]></title>
    <url>%2F2017%2F04%2F24%2Fget-started-with-flink-on-top-of-mesos-marathon%2F</url>
    <content type="text"><![CDATA[Based on CentOS 7 准备 rpm安装包准备 zookeeper mesos marathon 环境准备 三台机器的集群，网络互通，关闭防火墙和SELinux 1systemctl stop firewalld &amp;&amp; setenforce 0 节点 IP 部署服务 1 10.120.177.85 zookeeper、mesos-master、mesos-slave、marathon 2 10.120.181.94 zookeeper、mesos-master、mesos-slave、marathon 3 10.120.180.209 zookeeper、mesos-master、mesos-slave、marathon 安装 node1、node2、node3: 1234rpm -ivh zookeeper*.rpmyum install libevent libevent-devel -yrpm -ivh mesos*.rpmrpm -ivh marathon*.rpm 配置 zookeeper配置 node1: 1echo 1 &gt; /var/lib/zookeeper/myid node2: 1echo 2 &gt; /var/lib/zookeeper/myid node3: 1echo 3 &gt; /var/lib/zookeeper/myid node1、node2、node3配置/etc/zookeeper/zoo.cfg 123server.1=10.120.177.85:2888:3888server.2=10.120.181.94:2888:3888server.3=10.120.180.209:2888:3888 mesos配置 node1、node2、node3配置/etc/mesos/zk 1zk://10.120.177.85:2181,10.120.181.94:2181,10.120.180.209:2181/mesos node1、node2、node3: 12#集群中节点数为3echo 2 &gt; /etc/mesos-master/quorum marathon配置 node1、node2、node3: 12#用于生成marathon.jarmarathon 启动 node1、node2、node3: 1234systemctl restart zookeepersystemctl restart mesos-mastersystemctl restart mesos-slavemarathon run_jar --master zk://10.120.177.85:2181,10.120.181.94:2181,10.120.180.209:2181/mesos --zk zk://10.120.177.85:2181,10.120.181.94:2181,10.120.180.209:2181/marathon 可通过三个节点IP访问mesos webUI和marathon webUI，会重定向到zk选举出来的Master节点，以10.120.181.94为例: 12mesos webUI address: 10.120.181.94:5050marathon webUI address: 10.120.181.94:8080 部署Flink 编写json格式的marathon应用描述文件flink-example.json: 12345678&#123; "id": "flink", "cmd": "/home/flink-1.2.0/bin/mesos-appmaster.sh -Dmesos.master=zk://10.120.177.85:2181,10.120.181.94:2181,10.120.180.209:2181/mesos -Dmesos.initial-tasks=3 -Dmesos.resourcemanager.tasks.cpus=1.0 -Dmesos.resourcemanager.tasks.mem=1024", "cpus": 1, "mem": 1024, "disk": 2048, "instances": 1&#125; 通过Marathon WebUI提交或者使用curl命令提交: 1curl -X POST http://10.120.181.94:8080/v2/apps -d @flink-example.json -H "Content-type: application/json"]]></content>
      <categories>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Flink</tag>
        <tag>Mesos</tag>
        <tag>Marathon</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deploy flink on mesos marathon]]></title>
    <url>%2F2017%2F04%2F12%2Fdeploy-flink-on-mesos-marathon%2F</url>
    <content type="text"><![CDATA[Mesos部署 1.下载安装 从官网下载Mesos的rpm安装包（下载链接）并在所有集群节点中安装mesos 1rpm -ivh mesos-1.1.0*.rpm 注：可能会报libevent-devel依赖未安装，使用命令yum install libevent libevent-devel -y安装 2.集群部署 在/usr/etc/mesos目录下增加名为masters和slaves的文件，分别配上master节点和agent(worker)节点的ip列表，以换行分隔，以1个master节点2个agent节点为例： 在master节点所在机器的/usr/etc/mesos目录下，增加mesos-master-env.sh脚本（在相同目录下已存在模板），配置mesos工作目录环境变量export MESOS_work_dir=/xxx/xxx 在agent节点所在机器（在本例中，包括9.96.101.32和9.96.101.251两个节点）的/usr/etc/mesos目录下，增加mesos-agent-env.sh脚本（在相同目录下已存在模板），配置mesos master地址export MESOS_master=xx.xx.xx.xx:5050，和mesos工作目录环境变量export MESOS_work_dir=/xxx/xxx 运行/usr/sbin/mesos-start-cluster.sh启动集群 访问mesos web页面http://masterIP:5050可以查看mesos集群状态和agent列表等信息 3.部署Flink到Mesos 修改FLINK_HOME/conf/flink-conf.yaml，增加三个配置项：mesos.resourcemanager.tasks.container.type、mesos.master、mesos.initial-tasks，如下图所示，其中mesos.initial-tasks配置项表示taskmanager个数。 运行FLINK_HOME/bin/mesos-appmaster.sh向mesos注册schduler并启动jobmanager 查看mesos web页面，可以看到刚才启动的Flink集群在mesos中体现为1个Framework和2个Task（executor），每个java进程（mesos中的executor，flink中的taskmanager）对应一个sandbox 4.查看沙箱目录 沙箱是每个mesos executor工作时的临时目录。存在于agent节点的工作目录下，工作目录的配置见上文。沙箱的目录结构在官方文档中描述如下： 1234567891011root (&apos;--work_dir&apos;)|-- slaves| |-- latest (symlink)| |-- &lt;agent ID&gt;| |-- frameworks| |-- &lt;framework ID&gt;| |-- executors| |-- &lt;executor ID&gt;| |-- runs| |-- latest (symlink)| |-- &lt;container ID&gt; (Sandbox!) 登陆到本例中task所在节点9.96.101.251查看两个task各自的sandbox目录，包含了进程的标准输出、错误、日志，以及flink上传的jar包、配置文件和shell脚本等，与yarn的container目录很类似。 沙箱中的文件包含如下三部分： mesos在启动executor的task前获取的文件（flink文件夹） executor的输出（stderr，stdout） executor创建的文件（flink-taskmanager.log等） Marathon部署 1.简介 1Marathon is a production-proven Apache Mesos framework for container orchestration. Marathon provides a REST API for starting, stopping, and scaling applications. 翻译一下，Marathon是一个在工业界广泛使用的Mesos框架，用于容器编排。Marathon提供了一套REST API用于任务的启动、停止和扩容。 Marathon框架通常用于管理长时间运行的任务。 2.下载安装 从官网下载Marathon的rpm安装包（下载链接）并安装（推荐的安装方式） 1rpm -ivh marathon-1.4.0*.rpm 也可以从Marathon官网下载二进制的包（下载地址），使用$MARATHON_HOME/bin/start --master ip:port --zk zk://ip:port/marathon启动Marathon。 3.启动 命令样例如下，需要首先启动mesos集群和zk服务，不在此赘述。 1/usr/bin/marathon run_jar --master 10.120.177.85:5050 --zk zk://10.120.177.85:2181/marathon 注：不同版本marathon在zk上的leader信息不兼容，需确保zk中/marathon目录未被不同版本的marathon服务使用过 可以使用/usr/bin/marathon run_jar --help查看其它配置项说明。 4.提交任务 可以用两种方式提交应用，WebUI和curl。 打开Marathon WebUI（默认端口8080），点击Create Application，可以选在使用JSON模式描述任务信息，或者使用UI界面，本例中使用JSON方式，在cmd中写入运行的命令，点击右下角的Create Application提交。 使用curl方式提交命令格式如下： 1curl -X POST http://10.120.177.85:8080/v2/apps -d @basic-0.json -H "Content-type: application/json" 5.部署Flink 只需要将cmd的内容修改为$FLINK_HOME/bin/mesos-appmaster.sh -Dmesos.master=$MESOS_MASTER_IP:5050即可在Mesos中部署Flink集群。 涉及Flink的配置项列表参见Flink官网，资源相关的配置项包括mesos.initial-tasks、mesos.resourcemanager.tasks.mem和mesos.resourcemanager.tasks.cpus，分别代表启用多少个TaskManager以及每个TaskManager分配多少内存和CPU资源。 Mesos的资源分配使用DRF算法，参考论文：Dominant Resource Fairness: Fair Allocation of Multiple Resource Types，解决多种资源类型(主要考虑CPU和内存)的系统的公平资源分配问题。 使用如下json文件启动flink应用： 12345678&#123; "id": "/flink/flink1", "cmd": "/home/flink-1.2.0/bin/mesos-appmaster.sh -Dmesos.master=10.120.177.85:5050 -Dmesos.initial-tasks=3 -Dmesos.resourcemanager.tasks.cpus=1.0 -Dmesos.resourcemanager.tasks.mem=1024 -Djobmanager.web.port=-1", "cpus": 1, "mem": 1024, "disk": 2048, "instances": 1&#125; 使用Marathon的应用扩容功能，将实例数改为3： 在Mesos页面中查看部署结果： Scale Application的过程中，因JobManager RPC端口冲突，会重试数次，最终三个JobManager部署到三个不同的节点上。 再增加一个Flink应用，因集群资源有限，只有三个节点，因此在运行参数中增加-Djobmanager.web.port=8082 -Djobmanager.rpc.port=6124，避免端口冲突。 12345678&#123; "id": "/flink/flink2", "cmd": "/home/flink-1.2.0/bin/mesos-appmaster.sh -Dmesos.master=10.120.177.85:5050 -Dmesos.initial-tasks=3 -Dmesos.resourcemanager.tasks.cpus=1.0 -Dmesos.resourcemanager.tasks.mem=1024 -Djobmanager.web.port=-1 -Djobmanager.rpc.port=6124", "cpus": 1, "mem": 1024, "disk": 2048, "instances": 1&#125; 部署结果如下: 6.遇到的问题 在Marathon中部署跨节点Flink集群时，部署失败 查看TaskManager日志，报Association failed with [akka.tcp://flink@szv1000265118:6123] Connection refused: szv1000265118/10.120.181.94:6123而JobManager所在节点hostname为SZV1000265118，怀疑与hostname大小写有关。 相关github PR，修改hostname后问题解决。 1hostnamectl set-hostname &lt;hostname&gt; 在Marathon中Destroy Application后JobManager退出，但是TaskManager要等数分钟后才退出 查看日志发现TaskManager向JobManager注册多次后超时关闭，查看代码发现MesosApplicationMasterRunner.java中有如下代码，TaskManager向JobManager注册的最大超时时间为5分钟，在代码中写死，无配置项。 1private static final FiniteDuration TASKMANAGER_REGISTRATION_TIMEOUT = new FiniteDuration(5, TimeUnit.MINUTES); systemd Mesos守护进程问题 在Mesos集群重启时，经常发现agent进程起不来，ps -ef | grep mesos查看系统进程时发现运行/usr/sbin/mesos-stop-cluster.sh一段时间后，会出现mesos-master和mesos-slave进程。 rpm方式安装mesos时，会向systemd注册mesos相关服务，导致mesos相关进程在被杀掉后周期重启，见下图： 使用systemctl命令停止mesos相关服务后再启动Mesos集群，问题解决。 1234systemctl stop mesos-mastersystemctl stop mesos-slavepkill mesos/usr/sbin/mesos-start-cluster.sh CentOS防火墙问题导致Mesos、Marathon网页无法访问 1systemctl stop firewalld]]></content>
      <categories>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Flink</tag>
        <tag>Mesos</tag>
        <tag>Marathon</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tips in Functional Programming in Scala]]></title>
    <url>%2F2017%2F04%2F06%2Ffunctional-programming-in-scala-tips%2F</url>
    <content type="text"><![CDATA[update everyday(maybe weekly) partial application 123456789def compose[A,B,C](f: B =&gt; C, g: A =&gt; B): A =&gt; C = &#123; (a: A) =&gt; f(g(a))&#125;def curry[A,B,C](f: (A, B) =&gt; C): A =&gt; (B =&gt; C) = &#123; (a: A) =&gt; ((b: B) =&gt; f(a, b))&#125;def uncurry[A,B,C](f: A =&gt; B =&gt; C): (A, B) =&gt; C = &#123; (a: A, b: B) =&gt; f(a)(b)&#125;]]></content>
      <categories>
        <category>Scala</category>
      </categories>
      <tags>
        <tag>Scala</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Libprocess concepts]]></title>
    <url>%2F2017%2F03%2F29%2Flibprocess-tips%2F</url>
    <content type="text"><![CDATA[先看官方定义： 1Library that provides an actor style message-passing programming model (in C++). mesos代码中大篇幅引用libprocess，其中定义了大量异步编程的原语，包括future、promise这些在c++11中也有的概念，onReady、onAny等回调注册接口，以及then串接异步调用等等强大功能。 future／promise 概念 先看cplusplus.com官方定义： 12341. A future is an object that can retrieve a value from some provider object or function, properly synchronizing this access if in different threads.2. A promise is an object that can store a value of type T to be retreieved by a future object (possibly in another thread), offering a synchronization point. libprocess中实现了一套类似的future／promise（类比std::future／std::promise），其思想与c++很类似，future读，promise写，消费者持有future，生产者持有promise。 callback Future对象在函数返回值和入参间传递，存在多个消费者持有Future对象的多份拷贝的情况，因此Future使用一个共享指针成员维护唯一一份Data，在Data中记录Future状态和一系列callback，这些callback由onXXX接口注册，当生产者调用Promise的set等接口改变Future状态时将调用对应的callback。then也应用了callback机制。 then 先看示例代码： 12345Future&lt;string&gt; S = readyFuture() .then(lambda::bind(&amp;second, lambda::_1)) .then(lambda::bind(&amp;third, lambda::_1));string s = S.get(); 等同于： 12345Future&lt;bool&gt; A = oneFuture();Future&lt;int&gt; B = second(A.get());Future&lt;string&gt; S = third(B.get());string s = S.get();]]></content>
      <categories>
        <category>Mesos</category>
      </categories>
      <tags>
        <tag>libprocess</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mesos Containerizer]]></title>
    <url>%2F2017%2F03%2F24%2Fmesos-containerizer-tips%2F</url>
    <content type="text"><![CDATA[Mesos Containerizer是mesos agent的关键部件，提供容器化所需的服务。 位于agent和容器之间 启动、更新和销毁容器 提供容器间的隔离 上报容器状态 当前mesos支持以多种方式提供容器服务：Docker Containerizer、Mesos Containerizer以及两者混合。Mesos Containerizer更加稳定。 Mesos Containerizer主要包括以下三个组件： Launcher，负责启动和销毁容器进程 Isolator，最主要的功能组件，通过cgroup、namespace实现容器间资源隔离 Provisioner，提供容器镜像支持 容器启动的主要步骤如下： Isolator准备 包含创建cgroup目录和初始化cgroup subsystem相关参数等操作。举一个cgroup subsystem为memory的例子，经过CgroupsIsolatorProcess::prepare的调用过程后，新生成了如下cgroup目录，并设置相关初始化参数 ![](https://github.com/SeptimusZhu/flink-related/blob/master/pictures/mesos_cgroup_mem.PNG?raw=true) 2. 通过Launcher启动容器进程 Launcher的具体实现LinuxLauncher通过libprocess的actor模型调用LinuxLauncherProcess::fork创建容器子进程。主要包括创建subsystem为freezer的cgroup，并将子进程pid放入其中，如下图所示： ![](https://github.com/SeptimusZhu/flink-related/blob/master/pictures/mesos_cgroup_freezer.PNG?raw=true) 放入freezer cgroup的进程会暂停，直到隔离和fetch完成后，在exec时通过信号将子进程唤醒。 隔离容器进程 Isolator的具体实现有很多，主要包括cgroup、network cni等资源隔离接口，其中cgroup的隔离的过程就是将进程pid放入对应的cgroup中。具体实现在CgroupsIsolatorProcess::isolate ![](https://github.com/SeptimusZhu/flink-related/blob/master/pictures/mesos_cgroup_mem_isolate.PNG?raw=true) 4. fetch容器资源 fetch是一种在容器任务准备时将容器资源下载到沙箱目录的机制，为后续的exec过程做准备。 执行容器进程 之前fork出来的容器子进程被唤醒。]]></content>
      <categories>
        <category>Mesos</category>
      </categories>
      <tags>
        <tag>Mesos</tag>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flink Kafka consumer checkpoint机制]]></title>
    <url>%2F2017%2F02%2F07%2FFlink_Kafka_consumer_checkpoint%2F</url>
    <content type="text"><![CDATA[基于Apache Flink 1.3 1 概述 Flink中Kafka consumer算子是有状态的，Kafka offset就是该算子的状态。consumer算子深度集成了Flink checkpoint机制，保证了exactly-once（一条消息被处理一次，区别于at-least-once和at-most-once）。 checkpoint机制由Job Manager的CheckpointCoordinator模块控制，用户可以配置checkpoint周期（与savepoint不同，savepoint由用户在用户代码中手动触发）。当触发一次checkpoint，Job Manager会通知Task Manager，Task Manager收到通知后，异步执行所有StreamTask的快照，针对一个StreamTask，遍历所有operator，在operator上执行snapshotState并异步等待结果。当Job Manager的CheckpointCoordinator模块检测到checkpoint完成，会通知所有的Task Manager。 1.1 offset提交策略 开启checkpoint的情况下，不会自动向Kafka服务器提交offset确认请求，而是在Task Manager得到Job Manager下发的checkpoint完成通知后，通知所有算子任务，包括consumer算子，将完成checkpoint的offset提交回Kafka Server。 在09版本Fetcher类Kafka09Fetcher构造方法中，有如下代码，根据是否开启checkpoint决定是否设置自动提交offset。 1234// if checkpointing is enabled, we are not automatically committing to Kafka.kafkaProperties.setProperty( ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, Boolean.toString(!enableCheckpointing)); 注1：08老版本consumer算子的Fetcher中不存在此类代码，因08版本JM通知checkpoint完成后consumer算子将offset提交到zookeeper中保存，而09版本开始使用提交offset确认到Kafka服务器的策略实现checkpoint功能 注2：enable.auto.commit运行参数配置项在09之后的Flink kafka consumer应用中无效，无论是否配置了checkpoint 2 样例 开启checkpoint功能，需要在Flink的Kafka应用代码中加入如下代码： 1234//配置checkpoint间隔env.getCheckpointConfig().setCheckpointInterval(15000);//配置statebackendenv.setStateBackend(new FsStateBackend("file:////tmp/backend")); 为了直观说明checkpoint功能，编写测试代码如下，使用抛异常方式模拟流应用异常，当进入的事件数超过7个时流应用抛异常重启： 123456789101112131415161718192021222324252627public class ReadFromKafka &#123; static int count = 0; public static void main(String[] args) throws Exception &#123; StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); env.setParallelism(1); env.getCheckpointConfig().setCheckpointInterval(15000); env.setStateBackend(new FsStateBackend("file:////tmp/backend")); ParameterTool parameterTool = ParameterTool.fromArgs(args); DataStream&lt;String&gt; messageStream = env.addSource(new FlinkKafkaConsumer010&lt;&gt;( parameterTool.getRequired("topic"), new SimpleStringSchema(), parameterTool.getProperties())); messageStream.rebalance().map(new MapFunction&lt;String, String&gt;() &#123; @Override public String map(String s) throws Exception &#123; if (count++ == 7) &#123; count = 0; throw new Exception("Failed."); &#125; return s; &#125; &#125;).print(); env.execute(); &#125;&#125; 如下图所示，Kafka消息按如下时间点依次进入Kafka Consumer： 当partition 1的offset 5的消息进入Flink，进入测试代码中的异常分支，流应用重启后，重新向Kafka订阅消息，会从最近保存的checkpoint点的offset开始消费，在此例中，最终print结果中，只有partition 1 offset 4和partition 2 offset 3这两条消息会打印两次（partition之间消息不保序，同partition内保序），第二次异常分支由partition 1 offset 7的消息触发，因其为最近checkpoint后的第一条消息，因此流应用重启后继续从此开始消费。 3 流程 以下分别说明正常的checkpoint流程和异常的恢复流程 3.1 正常流程 下图为从Task Manager收到Job Manager的checkpoint消息后Flink Kafka Consumer算子一次完整checkpoint过程的线程时序图： 注：正常的checkpoint流程不涉及Consumer算子主线程。 3.2 异常恢复流程 Consumer算子初始化时，在FlinkKafkaConsumerBase.initializeState()方法中，会调用OperatorStateStore.getSerializableListState尝试从statebackend中获取最近一次checkpoint保存的offset信息，并将其保存在restoreToOffset中，当Consumer算子主线程开始运行时（FlinkKafkaConsumerBase.run())，先尝试从restoreToOffset中获取offset，并保存到Consumer算子主线程和Kafka Consumer线程共有的partition集合引用中，从而Kafka Consumer线程可以从该checkpoint指定的partition offset中开始消费消息。]]></content>
      <categories>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Flink</tag>
        <tag>Kafka</tag>
      </tags>
  </entry>
</search>
