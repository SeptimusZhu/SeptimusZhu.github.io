<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Flink SQL 原理及使用入门]]></title>
    <url>%2F2018%2F10%2F31%2FFlink%20SQL%20%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[基于Apache Flink 1.6.x 1 Get StartedFlink SQL是Flink高层API，语法遵循ANSI SQL标准。示例如下 1234SELECT car_id, MAX(speed), COUNT(speed)FROM drive_dataWHERE speed &gt; 90GROUP BY TUMBLE (proctime, INTERVAL '30' SECOND), car_id Flink SQL是在Flink Table API的基础上发展起来的，与上述示例对应的Table API示例如下 1234table.where('speed &gt; 90) .window(Tumble over 30.second on 'proctime as 'w) .groupBy('w, 'car_id) .select('car_id, 'speed.max, 'speed.count) 上述示例使用Scala代码，结合隐式转换和中缀表示等Scala语法，Table API代码看起来非常接近SQL表达。 2 架构原理老版本的Table API通过类似链式调用的写法，构造一棵Table Operator树，并对各个树节点做代码生成，转化成Flink低层API调用代码，即DataStream/DataSet API。 从2016年开始，开源社区已经有大量SQL-on-Hadoop的成熟解决方案，包括Apache Hive、Apache Impala、Apache Drill等等，都依赖Apache Calcite提供的SQL解析优化能力，Apache Calcite当时已经是一个非常流行的业界标准SQL解析和优化框架。于此同时，随着在实时分析领域中Flink的应用场景增加，对SQL API的呼声渐高，于是社区开始在Apache Calcite的基础上构建新版本的Table API，并增加SQL API支持。 新版本的Table &amp; SQL API在原有的Table API基础上，由Calcite提供SQL解析和优化能力，将Table API调用和SQL查询统一转换成Calcite逻辑执行计划（Calcite RelNode树），并对此进行优化和代码生成，最终同样转化成Flink DataStream/DataSet API调用代码。 3 DDL &amp; DML完整的SQL语法由DDL（data definition language）和DML（data manipulation language）两部分组成。Flink SQL目前只支持DML语法，而包含数据流定义的DDL语法仍需通过代码实现。 国内各大公有云厂商中，阿里云和华为云提供了基于Flink SQL的实时流计算服务，各自定义了一套DDL语法，语法大同小异。以华为云为例，数据流定义以CREATE STREAM为关键字，具体的DDL写法示例如下 123456789101112131415161718CREATE SOURCE STREAM driver_behavior (car_id STRING, speed INT, collect_time LONG)WITH ( type = "kafka", kafka_bootstrap_servers = "10.10.10.10:3456,10.10.10.20:3456", kafka_group_id = "group1", kafka_topic = "topic1", encode = "csv", field_delimiter = ",") TIMESTAMP BY collect_time.ROWTIME;CREATE SINK STREAM over_speed_warning (message STRING)WITH ( type = "smn", region = "cn-north-1", topic_urn = "urn:smn:cn-north-1:38834633fd6f4bae813031b5985dbdea:warning", message_subject = "title", message_column = "message"); DDL中包含输入数据流和输出数据流定义，描述实时流计算的数据上下游生态组件，在上述例子中，输入流（SOURCE STREAM）类型是Kafka，WITH子句描述了Kafka消费者相关配置。输出流（SINK STREAM）类型是SMN，是华为云消息通知服务的缩写，用于短信和邮件通知。 数据从Kafka流入，向SMN服务流出，而中间的数据处理逻辑由DML实现，具体的DML写法示例如下 123456789INSERT INTO over_speed_warningSELECT "your car speed (" || CAST(speed as CHAR(20)) || ") exceeds the maximum speed."FROM ( SELECT car_id, MAX(speed) AS speed, COUNT(speed) AS overspeed_count FROM driver_behavior WHERE speed &gt; 90 GROUP BY TUMBLE (collect_time, INTERVAL '30' SECOND), car_id)WHERE overspeed_count &gt;= 3; 以上DML语句，描述了在30秒内车辆累计超速三次时，向作为输出流的下游SMN组件输出告警消息。DML语句中INSERT INTO关键字后紧接着输出流名，而FROM关键字后紧接着输入流名，SELECT 子句表达输出的内容，WHERE子句表达输出需要满足的过滤条件。上述例子使用到了SQL子查询，外层FROM后跟着一整个SELECT子句，为了方便理解，我们也可以把子查询语法转化成等价的临时流定义表达，在华为云实时流计算服务的DDL语法中支持了这种特性，与上述DML写法等价的示例如下 123456789101112CREATE TEMP STREAM over_speed_info (car_id STRING, speed INT, overspeed_count INT);INSERT INTO over_speed_infoSELECT car_id, MAX(speed) AS speed, COUNT(speed) AS overspeed_countFROM driver_behaviorWHERE speed &gt; 90GROUP BY TUMBLE (collect_time, INTERVAL '30' SECOND), car_id;INSERT INTO over_speed_warningSELECT "your car speed (" || CAST(speed as CHAR(20)) || ") exceeds the maximum speed."FROM over_speed_infoWHERE overspeed_count &gt;= 3; 通过TEMP STREAM 语法定义临时流，可以将带有子查询的SQL语法平铺表达，串接数据流逻辑，更容易理解。 4 语法Flink SQL的核心部分是DML语法，基础的DML语法包含笛卡尔积（单表情况下只有Scan操作）、选择（Filter）和投影（Projection）三个数据操作部分，三者分别对应FROM子句、WHERE 子句和SELECT子句，这三个部分的顺序代表了DML语句的逻辑执行顺序。较为进阶的语法包含聚合、窗口和连接（JOIN）等常用语法，以及排序、限制和集合等非常用语法。下表简单列举Flink SQL基础和常用的进阶DML语法句式并加以说明，其他语法元素和内建函数等详细内容，可参考Flink SQL文档 基础语法 操作 样例 Scan / Filter / Projection SELECT car_id, speed FROM drive_data WHERE speed &gt; 90 Scan / FIlter / Projection / Insert INSERT INTO overspeed SELECT id , speed FROM drive_data WHERE speed &gt; 90 聚合语法 操作 样例 备注 GroupBy Aggregation SELECT MAX(speed) FROM drive_data GROUP BY car_id GroupBy Window Aggregation SELECT car_id, MAX(speed) FROM drive_data GROUP BY TUMBLE(proctime, INTERVAL ‘1’ MINUTE), car_id GroupBy窗口每个聚合周期输出一批聚合结果 Over Window Aggregation SELECT MAX(speed) OVER ( PARTITION BY car_id ORDER BY proctime RANGE BETWEEN INTERVAL ‘30’ SECOND PRECEDING AND CURRENT ROW) FROM drive_data Over窗口每进入一条数据就输出一条聚合结果，且所有的投影属性的Over窗口必须一致 连接语法 操作 样例 备注 Inner Euiq-join SELECT * FROM drive_data INNER JOIN car_info ON drive_data.car_id = car_info.id 当前只支持等值连接 Time-windowed Join SELECT * FROM drive_data d, camera_data c WHERE d.car_id = c.car_id AND d.proctime BETWEEN c.proctime - INTERVAL ‘30’ SECOND AND c.proctime Table Join SELECT * FROM drive_data INNER JOIN car_info ON drive_data.car_id = car_info.id 流表Join语法和流流Join语法类似，Flink SQL目前不支持流表Join，阿里云和华为云实时流计算服务的SQL语法是支持的 5 场景目前Flink SQL的应用场景主要包括ETL实时入库、实时大屏、实时告警等等。 在IoT领域和车联网领域也大量存在潜在的使用场景，华为云实时流计算服务提供了针对这些场景的SQL扩展，包括地理函数，CEP SQL等支持，还支持Streaming ML语法用SQL表达多种实时机器学习算法，包括随机森林算法实现异常检测等场景。]]></content>
      <categories>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Flink</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Anti GFW guide]]></title>
    <url>%2F2018%2F07%2F17%2FAnti-GFW-guide%2F</url>
    <content type="text"><![CDATA[公司内网环境有美国代理，但Wi-Fi/4G环境是国内网络，使用Mac与手机时诸多不便，科学上网简要步骤记录如下 ss服务器购买vps或者ecs，国内外提供商都有，网上随便搜搜，各大云厂商有折扣就买，一个月几十块。我之前用的是华为云香港区的ecs，选centos系统，KeyPair登陆，绑上弹性IP，安全组开放TCP入方向443端口。1234easy_install pipyum install gitpip install git+https://github.com/shadowsocks/shadowsocks.git@masterssserver -p 443 -k yourpswd -m aes-256-cfb --user nobody -d start vultr有25+3=28刀优惠，最便宜的ipv4机器每个月3.5刀，相当于免费用8个月，注册链接https://www.vultr.com/promo25b?service=promo25b 123yum install net-toolswget -N --no-check certificate https://raw.githubusercontent.com/ToyoDAdoubi/doubi/master/ssr.sh &amp;&amp; chmod +x ssr.sh &amp;&amp; ./ssr.shwget --no-check-certificate https://github.com/teddysun/across/raw/master/bbr.sh &amp;&amp; chmod +x bbr.sh &amp;&amp; ./bbr.sh ss客户端 iPhone我手机没越狱，在闲鱼买了个香港或者美国appleid，下载shadowrocket、kite、openwingy等软件，配置服务器ip密码加密方式即可 MacBook 网页shadowsocks官网下载客户端（需先用vpn软件翻墙）shadowsocksX/shadowsocksX-NG，安装后配置与iPhone类似 MacBook 终端终端默认无法使用http代理，使用brew、sbt、git等命令时特别慢，需要安装privoxy（shadowsocksX-NG自带），在shell的rc脚本中配置（~/.zshrc) 123alias proxy=&apos;export all_proxy=socks5://127.0.0.1:1080&apos;alias unproxy=&apos;unset all_proxy&apos;export JAVA_OPTS=&quot;$JAVA_OPTS -Dhttp.proxyHost=127.0.0.1 -Dhttp.proxyPort=8118&quot;]]></content>
      <categories>
        <category>科学上网</category>
      </categories>
      <tags>
        <tag>GFW</tag>
        <tag>shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mesos net_cls test]]></title>
    <url>%2F2017%2F05%2F27%2Fmesos-net-cls-test%2F</url>
    <content type="text"><![CDATA[1.mesos启动参数配置slave启动参数配置，增加net_cls 1echo cgroups/cpu,cgroups/mem,cgroups/net_cls &gt; /etc/mesos-slave/isolation 增加mesos-slave启动参数--cgroups_net_cls_primary_handle=0x0001，可以通过修改/usr/bin/mesos-init-wrapper脚本实现，最终mesos-slave启动参数如下： 1/usr/sbin/mesos-slave --master=zk://10.120.177.85:2181,10.120.181.94:2181,10.120.180.209:2181/mesos --log_dir=/var/log/mesos --cgroups_net_cls_primary_handle=0x0001 --containerizers=mesos --isolation=cgroups/cpu,cgroups/mem,cgroups/net_cls --work_dir=/var/lib/meso 此时mesos会为每个容器分配一个16位的cgroups_net_cls_secondary_handle，和cgroups_net_cls_primary_handle(0x0001)一起组成一个classid。 2. 启动应用使用marathon提交nc命令行应用，向对端发数据： 12345678&#123; "id": "/basic-023", "cmd": "yes ssssssssssssssssssssss|nc 10.162.174.188 5567", "cpus": 1, "mem": 10, "disk": 0, "instances": 1&#125; 使用nethogs工具查看进程流量： 3. 启用流控规则查看容器进程的classid： 65538 = 0x00010002 使用tc工具配置规则： 12345tc qdisc del dev eth0 roottc qdisc add dev eth0 root handle 1: htbtc class add dev eth0 parent 1: classid 1: htb rate 1000mbit ceil 1000mbittc class add dev eth0 parent 1: classid 1:2 htb rate 1mbittc filter add dev eth0 protocol ip parent 1:0 prio 1 handle 1:2 cgroup 查看进行流控后的容器进程流量：]]></content>
      <categories>
        <category>Mesos</category>
      </categories>
      <tags>
        <tag>Mesos</tag>
        <tag>net_cls</tag>
        <tag>流控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Get Started with Flink on top of Mesos Marathon]]></title>
    <url>%2F2017%2F04%2F24%2Fget-started-with-flink-on-top-of-mesos-marathon%2F</url>
    <content type="text"><![CDATA[Based on CentOS 7 准备rpm安装包准备zookeeper mesos marathon 环境准备三台机器的集群，网络互通，关闭防火墙和SELinux 1systemctl stop firewalld &amp;&amp; setenforce 0 节点 IP 部署服务 1 10.120.177.85 zookeeper、mesos-master、mesos-slave、marathon 2 10.120.181.94 zookeeper、mesos-master、mesos-slave、marathon 3 10.120.180.209 zookeeper、mesos-master、mesos-slave、marathon 安装node1、node2、node3: 1234rpm -ivh zookeeper*.rpmyum install libevent libevent-devel -yrpm -ivh mesos*.rpmrpm -ivh marathon*.rpm 配置zookeeper配置node1: 1echo 1 &gt; /var/lib/zookeeper/myid node2: 1echo 2 &gt; /var/lib/zookeeper/myid node3: 1echo 3 &gt; /var/lib/zookeeper/myid node1、node2、node3配置/etc/zookeeper/zoo.cfg 123server.1=10.120.177.85:2888:3888server.2=10.120.181.94:2888:3888server.3=10.120.180.209:2888:3888 mesos配置node1、node2、node3配置/etc/mesos/zk 1zk://10.120.177.85:2181,10.120.181.94:2181,10.120.180.209:2181/mesos node1、node2、node3: 12#集群中节点数为3echo 2 &gt; /etc/mesos-master/quorum marathon配置node1、node2、node3: 12#用于生成marathon.jarmarathon 启动node1、node2、node3: 1234systemctl restart zookeepersystemctl restart mesos-mastersystemctl restart mesos-slavemarathon run_jar --master zk://10.120.177.85:2181,10.120.181.94:2181,10.120.180.209:2181/mesos --zk zk://10.120.177.85:2181,10.120.181.94:2181,10.120.180.209:2181/marathon 可通过三个节点IP访问mesos webUI和marathon webUI，会重定向到zk选举出来的Master节点，以10.120.181.94为例: 12mesos webUI address: 10.120.181.94:5050marathon webUI address: 10.120.181.94:8080 部署Flink编写json格式的marathon应用描述文件flink-example.json: 12345678&#123; "id": "flink", "cmd": "/home/flink-1.2.0/bin/mesos-appmaster.sh -Dmesos.master=zk://10.120.177.85:2181,10.120.181.94:2181,10.120.180.209:2181/mesos -Dmesos.initial-tasks=3 -Dmesos.resourcemanager.tasks.cpus=1.0 -Dmesos.resourcemanager.tasks.mem=1024", "cpus": 1, "mem": 1024, "disk": 2048, "instances": 1&#125; 通过Marathon WebUI提交或者使用curl命令提交: 1curl -X POST http://10.120.181.94:8080/v2/apps -d @flink-example.json -H &quot;Content-type: application/json&quot;]]></content>
      <categories>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Mesos</tag>
        <tag>Marathon</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deploy flink on mesos marathon]]></title>
    <url>%2F2017%2F04%2F12%2Fdeploy-flink-on-mesos-marathon%2F</url>
    <content type="text"><![CDATA[Mesos部署1.下载安装从官网下载Mesos的rpm安装包（下载链接）并在所有集群节点中安装mesos 1rpm -ivh mesos-1.1.0*.rpm 注：可能会报libevent-devel依赖未安装，使用命令yum install libevent libevent-devel -y安装 2.集群部署 在/usr/etc/mesos目录下增加名为masters和slaves的文件，分别配上master节点和agent(worker)节点的ip列表，以换行分隔，以1个master节点2个agent节点为例： 在master节点所在机器的/usr/etc/mesos目录下，增加mesos-master-env.sh脚本（在相同目录下已存在模板），配置mesos工作目录环境变量export MESOS_work_dir=/xxx/xxx 在agent节点所在机器（在本例中，包括9.96.101.32和9.96.101.251两个节点）的/usr/etc/mesos目录下，增加mesos-agent-env.sh脚本（在相同目录下已存在模板），配置mesos master地址export MESOS_master=xx.xx.xx.xx:5050，和mesos工作目录环境变量export MESOS_work_dir=/xxx/xxx 运行/usr/sbin/mesos-start-cluster.sh启动集群 访问mesos web页面http://masterIP:5050可以查看mesos集群状态和agent列表等信息 3.部署Flink到Mesos 修改FLINK_HOME/conf/flink-conf.yaml，增加三个配置项：mesos.resourcemanager.tasks.container.type、mesos.master、mesos.initial-tasks，如下图所示，其中mesos.initial-tasks配置项表示taskmanager个数。 运行FLINK_HOME/bin/mesos-appmaster.sh向mesos注册schduler并启动jobmanager 查看mesos web页面，可以看到刚才启动的Flink集群在mesos中体现为1个Framework和2个Task（executor），每个java进程（mesos中的executor，flink中的taskmanager）对应一个sandbox 4.查看沙箱目录沙箱是每个mesos executor工作时的临时目录。存在于agent节点的工作目录下，工作目录的配置见上文。沙箱的目录结构在官方文档中描述如下： 1234567891011root (&apos;--work_dir&apos;)|-- slaves| |-- latest (symlink)| |-- &lt;agent ID&gt;| |-- frameworks| |-- &lt;framework ID&gt;| |-- executors| |-- &lt;executor ID&gt;| |-- runs| |-- latest (symlink)| |-- &lt;container ID&gt; (Sandbox!) 登陆到本例中task所在节点9.96.101.251查看两个task各自的sandbox目录，包含了进程的标准输出、错误、日志，以及flink上传的jar包、配置文件和shell脚本等，与yarn的container目录很类似。 沙箱中的文件包含如下三部分： mesos在启动executor的task前获取的文件（flink文件夹） executor的输出（stderr，stdout） executor创建的文件（flink-taskmanager.log等） Marathon部署1.简介1Marathon is a production-proven Apache Mesos framework for container orchestration. Marathon provides a REST API for starting, stopping, and scaling applications. 翻译一下，Marathon是一个在工业界广泛使用的Mesos框架，用于容器编排。Marathon提供了一套REST API用于任务的启动、停止和扩容。 Marathon框架通常用于管理长时间运行的任务。 2.下载安装从官网下载Marathon的rpm安装包（下载链接）并安装（推荐的安装方式） 1rpm -ivh marathon-1.4.0*.rpm 也可以从Marathon官网下载二进制的包（下载地址），使用$MARATHON_HOME/bin/start --master ip:port --zk zk://ip:port/marathon启动Marathon。 3.启动命令样例如下，需要首先启动mesos集群和zk服务，不在此赘述。 1/usr/bin/marathon run_jar --master 10.120.177.85:5050 --zk zk://10.120.177.85:2181/marathon 注：不同版本marathon在zk上的leader信息不兼容，需确保zk中/marathon目录未被不同版本的marathon服务使用过 可以使用/usr/bin/marathon run_jar --help查看其它配置项说明。 4.提交任务可以用两种方式提交应用，WebUI和curl。 打开Marathon WebUI（默认端口8080），点击Create Application，可以选在使用JSON模式描述任务信息，或者使用UI界面，本例中使用JSON方式，在cmd中写入运行的命令，点击右下角的Create Application提交。 使用curl方式提交命令格式如下： 1curl -X POST http://10.120.177.85:8080/v2/apps -d @basic-0.json -H &quot;Content-type: application/json&quot; 5.部署Flink只需要将cmd的内容修改为$FLINK_HOME/bin/mesos-appmaster.sh -Dmesos.master=$MESOS_MASTER_IP:5050即可在Mesos中部署Flink集群。 涉及Flink的配置项列表参见Flink官网，资源相关的配置项包括mesos.initial-tasks、mesos.resourcemanager.tasks.mem和mesos.resourcemanager.tasks.cpus，分别代表启用多少个TaskManager以及每个TaskManager分配多少内存和CPU资源。 Mesos的资源分配使用DRF算法，参考论文：Dominant Resource Fairness: Fair Allocation of Multiple Resource Types，解决多种资源类型(主要考虑CPU和内存)的系统的公平资源分配问题。 使用如下json文件启动flink应用： 12345678&#123; "id": "/flink/flink1", "cmd": "/home/flink-1.2.0/bin/mesos-appmaster.sh -Dmesos.master=10.120.177.85:5050 -Dmesos.initial-tasks=3 -Dmesos.resourcemanager.tasks.cpus=1.0 -Dmesos.resourcemanager.tasks.mem=1024 -Djobmanager.web.port=-1", "cpus": 1, "mem": 1024, "disk": 2048, "instances": 1&#125; 使用Marathon的应用扩容功能，将实例数改为3： 在Mesos页面中查看部署结果： Scale Application的过程中，因JobManager RPC端口冲突，会重试数次，最终三个JobManager部署到三个不同的节点上。 再增加一个Flink应用，因集群资源有限，只有三个节点，因此在运行参数中增加-Djobmanager.web.port=8082 -Djobmanager.rpc.port=6124，避免端口冲突。 12345678&#123; "id": "/flink/flink2", "cmd": "/home/flink-1.2.0/bin/mesos-appmaster.sh -Dmesos.master=10.120.177.85:5050 -Dmesos.initial-tasks=3 -Dmesos.resourcemanager.tasks.cpus=1.0 -Dmesos.resourcemanager.tasks.mem=1024 -Djobmanager.web.port=-1 -Djobmanager.rpc.port=6124", "cpus": 1, "mem": 1024, "disk": 2048, "instances": 1&#125; 部署结果如下: 6.遇到的问题 在Marathon中部署跨节点Flink集群时，部署失败 查看TaskManager日志，报Association failed with [akka.tcp://flink@szv1000265118:6123] Connection refused: szv1000265118/10.120.181.94:6123而JobManager所在节点hostname为SZV1000265118，怀疑与hostname大小写有关。 相关github PR，修改hostname后问题解决。 1hostnamectl set-hostname &lt;hostname&gt; 在Marathon中Destroy Application后JobManager退出，但是TaskManager要等数分钟后才退出 查看日志发现TaskManager向JobManager注册多次后超时关闭，查看代码发现MesosApplicationMasterRunner.java中有如下代码，TaskManager向JobManager注册的最大超时时间为5分钟，在代码中写死，无配置项。 1private static final FiniteDuration TASKMANAGER_REGISTRATION_TIMEOUT = new FiniteDuration(5, TimeUnit.MINUTES); systemd Mesos守护进程问题 在Mesos集群重启时，经常发现agent进程起不来，ps -ef | grep mesos查看系统进程时发现运行/usr/sbin/mesos-stop-cluster.sh一段时间后，会出现mesos-master和mesos-slave进程。 rpm方式安装mesos时，会向systemd注册mesos相关服务，导致mesos相关进程在被杀掉后周期重启，见下图： 使用systemctl命令停止mesos相关服务后再启动Mesos集群，问题解决。 1234systemctl stop mesos-mastersystemctl stop mesos-slavepkill mesos/usr/sbin/mesos-start-cluster.sh CentOS防火墙问题导致Mesos、Marathon网页无法访问 1systemctl stop firewalld]]></content>
      <categories>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>Mesos</tag>
        <tag>Marathon</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tips in Functional Programming in Scala]]></title>
    <url>%2F2017%2F04%2F06%2Ffunctional-programming-in-scala-tips%2F</url>
    <content type="text"><![CDATA[update everyday(maybe weekly) partial application 123456789def compose[A,B,C](f: B =&gt; C, g: A =&gt; B): A =&gt; C = &#123; (a: A) =&gt; f(g(a))&#125;def curry[A,B,C](f: (A, B) =&gt; C): A =&gt; (B =&gt; C) = &#123; (a: A) =&gt; ((b: B) =&gt; f(a, b))&#125;def uncurry[A,B,C](f: A =&gt; B =&gt; C): (A, B) =&gt; C = &#123; (a: A, b: B) =&gt; f(a)(b)&#125;]]></content>
      <categories>
        <category>Scala</category>
      </categories>
      <tags>
        <tag>Scala</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Libprocess concepts]]></title>
    <url>%2F2017%2F03%2F29%2Flibprocess-tips%2F</url>
    <content type="text"><![CDATA[先看官方定义： 1Library that provides an actor style message-passing programming model (in C++). mesos代码中大篇幅引用libprocess，其中定义了大量异步编程的原语，包括future、promise这些在c++11中也有的概念，onReady、onAny等回调注册接口，以及then串接异步调用等等强大功能。 future／promise 概念先看cplusplus.com官方定义： 12341. A future is an object that can retrieve a value from some provider object or function, properly synchronizing this access if in different threads.2. A promise is an object that can store a value of type T to be retreieved by a future object (possibly in another thread), offering a synchronization point. libprocess中实现了一套类似的future／promise（类比std::future／std::promise），其思想与c++很类似，future读，promise写，消费者持有future，生产者持有promise。 callbackFuture对象在函数返回值和入参间传递，存在多个消费者持有Future对象的多份拷贝的情况，因此Future使用一个共享指针成员维护唯一一份Data，在Data中记录Future状态和一系列callback，这些callback由onXXX接口注册，当生产者调用Promise的set等接口改变Future状态时将调用对应的callback。then也应用了callback机制。 then先看示例代码： 12345Future&lt;string&gt; S = readyFuture() .then(lambda::bind(&amp;second, lambda::_1)) .then(lambda::bind(&amp;third, lambda::_1));string s = S.get(); 等同于： 12345Future&lt;bool&gt; A = oneFuture();Future&lt;int&gt; B = second(A.get());Future&lt;string&gt; S = third(B.get());string s = S.get();]]></content>
      <categories>
        <category>Mesos</category>
      </categories>
      <tags>
        <tag>libprocess</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mesos Containerizer]]></title>
    <url>%2F2017%2F03%2F24%2Fmesos-containerizer-tips%2F</url>
    <content type="text"><![CDATA[Mesos Containerizer是mesos agent的关键部件，提供容器化所需的服务。 位于agent和容器之间 启动、更新和销毁容器 提供容器间的隔离 上报容器状态 当前mesos支持以多种方式提供容器服务：Docker Containerizer、Mesos Containerizer以及两者混合。Mesos Containerizer更加稳定。 Mesos Containerizer主要包括以下三个组件： Launcher，负责启动和销毁容器进程 Isolator，最主要的功能组件，通过cgroup、namespace实现容器间资源隔离 Provisioner，提供容器镜像支持 容器启动的主要步骤如下： Isolator准备 包含创建cgroup目录和初始化cgroup subsystem相关参数等操作。举一个cgroup subsystem为memory的例子，经过CgroupsIsolatorProcess::prepare的调用过程后，新生成了如下cgroup目录，并设置相关初始化参数 通过Launcher启动容器进程 Launcher的具体实现LinuxLauncher通过libprocess的actor模型调用LinuxLauncherProcess::fork创建容器子进程。主要包括创建subsystem为freezer的cgroup，并将子进程pid放入其中，如下图所示：放入freezer cgroup的进程会暂停，直到隔离和fetch完成后，在exec时通过信号将子进程唤醒。 隔离容器进程 Isolator的具体实现有很多，主要包括cgroup、network cni等资源隔离接口，其中cgroup的隔离的过程就是将进程pid放入对应的cgroup中。具体实现在CgroupsIsolatorProcess::isolate fetch容器资源 fetch是一种在容器任务准备时将容器资源下载到沙箱目录的机制，为后续的exec过程做准备。 执行容器进程 之前fork出来的容器子进程被唤醒。]]></content>
      <categories>
        <category>Mesos</category>
      </categories>
      <tags>
        <tag>Mesos</tag>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F03%2F24%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
